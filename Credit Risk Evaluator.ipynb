{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop('target', axis=1)\n",
    "X_train = train_df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder().fit(train_df[\"target\"])\n",
    "y_train = encoder.transform(train_df[\"target\"])\n",
    "y_test = encoder.transform(test_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing dummy variables to testing set\n",
    "X_train_dummies = pd.get_dummies(X_train)\n",
    "X_test_dummies = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debt_settlement_flag_Y\n"
     ]
    }
   ],
   "source": [
    "# Finding the missing column\n",
    "for col in X_train_dummies.columns:\n",
    "    if col not in X_test_dummies.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the missing column\n",
    "X_test_dummies['debt_settlement_flag_Y'] = 0\n",
    "X_test_dummies = X_test_dummies[X_train_dummies.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction (Unscaled)\n",
    "For this specific case, I believe that there will be several contributing factors to determine if our target will be high-risk or low-risk. And because of that, I think that the Logistic Regression model will perform better and will either be overfit slightly or not at all. this is because it will be better at taking all of the variables to create a more accurate test model. I think the Random Forest Classifier will also perform well, but not as well as the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.65311986863711\n",
      "Testing Data Score: 0.5076563164610803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Khazzaka\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_dummies, y_train)\n",
    "print(f\"Training Data Score: {lr.score(X_train_dummies, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr.score(X_test_dummies, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7405582922824302\n",
      "Testing Data Score: 0.620374308804764\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=350, max_depth=3)\n",
    "rf.fit(X_train_dummies, y_train)\n",
    "print(f\"Training Data Score: {rf.score(X_train_dummies, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf.score(X_test_dummies, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis (Unscaled)\n",
    "To my surprise, the RFC model actually performed slightly better, and was less overfit than the LR model. I did not expect this result but I believe that it could potentially be due to the data being unscaled. It will be interesting to see how that changes our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X_train_dummies)\n",
    "\n",
    "# Use the scaler on X_train and X_test\n",
    "X_train_scaled = scaler.transform(X_train_dummies)\n",
    "X_test_scaled = scaler.transform(X_test_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction (Scaled)\n",
    "It is my thought that after scaling the data, we will see significant improvements in the testing score of both models and they will no longer be overfit. But i still think that the Logistic Regression model will perform better overall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.710919540229885\n",
      "Testing Data Score: 0.7598894087622289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Khazzaka\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {lr.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7300492610837438\n",
      "Testing Data Score: 0.6050616758826032\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {rf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.72622824e-03, 9.75894899e-02, 1.71763305e-02, 9.68490538e-04,\n",
       "       3.62476782e-04, 7.71801620e-05, 2.02532164e-03, 2.50924274e-04,\n",
       "       2.00362469e-06, 1.32179578e-03, 3.10559253e-04, 2.40083206e-02,\n",
       "       2.59709321e-02, 1.05927766e-01, 9.92536923e-02, 7.84769279e-02,\n",
       "       1.25625542e-01, 6.46810234e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.31356184e-01, 3.32731339e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.00085355e-05, 9.89266726e-04, 1.36566618e-03, 2.06291264e-05,\n",
       "       7.33957603e-05, 1.93512282e-04, 4.33067929e-04, 3.76614309e-04,\n",
       "       3.42738479e-03, 2.28007028e-03, 4.91863136e-03, 3.68565063e-03,\n",
       "       2.76950143e-03, 3.86050277e-03, 5.78444269e-04, 2.83647427e-04,\n",
       "       3.34822291e-03, 1.11154087e-02, 1.64476418e-03, 6.11780939e-03,\n",
       "       9.81017103e-04, 0.00000000e+00, 0.00000000e+00, 1.66201995e-03,\n",
       "       5.24179237e-03, 1.71907875e-03, 3.60666306e-03, 1.57450698e-03,\n",
       "       2.02779649e-03, 6.90166357e-03, 9.02998910e-04, 1.93952813e-04,\n",
       "       4.94276132e-04, 2.82651100e-05, 6.56837808e-05, 4.59489962e-04,\n",
       "       4.07476911e-04, 2.87807061e-04, 7.97921691e-04, 6.70927857e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.48732166e-04, 8.47565141e-03,\n",
       "       2.61362583e-03, 1.31522864e-03, 9.05058767e-06, 0.00000000e+00,\n",
       "       3.59886026e-03, 8.01210290e-04, 6.07054308e-03, 4.42626733e-04,\n",
       "       0.00000000e+00, 7.28580734e-05, 8.82620564e-06, 2.02732985e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.30526812e-03, 0.00000000e+00,\n",
       "       6.41951717e-05, 0.00000000e+00, 5.39420222e-05, 0.00000000e+00,\n",
       "       8.37729483e-03, 8.15318844e-03, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the impacts of each variable\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis (Scaled)\n",
    "After scaling, our Logistic Regression model was no longer overfitting, and we also were able to get a higher testing score. However,  the Random Forest Classifier testing score actually got worse and remained overfit, which was the opposite of my predition. My predictions for Logistic Regression were right, and it has proven to be the better model after I scaled the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
